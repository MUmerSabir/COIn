{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_metrics\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Embedding\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataset\n",
    "#data=pd.read_csv('gender-classifier.csv',encoding = \"ISO-8859-1\")\n",
    "data=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying pre-processing steps to remove stopwords and words of size less than 2\n",
    "data['tweet'] = data['tweet'].apply(lambda x: x.split())\n",
    "wordsEng = stopwords.words('english')\n",
    "data['tweet'] = data['tweet'].apply(lambda x:[item for item in x if item not in wordsEng])\n",
    "data['tweet'] = data['tweet'].apply(lambda x: [w for w in x if len(w)>2])\n",
    "data['tweet'] = data['tweet'].apply(lambda x: \" \".join(x))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing airline company names as pre-processing\n",
    "testList=[]\n",
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "for t in range(len(data)):\n",
    "    testList.append(strip_all_entities(strip_links(data['tweet'][t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting testList[] list into dataframe for further processing\n",
    "dat = pd.DataFrame(np.array(testList))\n",
    "dat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying pre-processing to remove special symbols, numbers and converting into lower case\n",
    "sw = stopwords.words('english')\n",
    "twitterSentiment=[]\n",
    "for i in range(len(dat)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ',dat[0][i])\n",
    "    review = re.sub('[/(){}\\[\\]\\|@!,;]', ' ',dat[0][i])\n",
    "    review = re.sub('[^0-9a-zA-Z #+_♥️]', ' ',dat[0][i])#Remove bad symbols\n",
    "    \n",
    "    review = re.sub(r'\\d+', '',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [token for token in review if token not in sw]\n",
    "    review=' '.join(review)\n",
    "    review=' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",review).split())\n",
    "    twitterSentiment.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train = count_vectorizer.fit_transform(X_train)\n",
    "X_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import preprocessing\n",
    "#lab_enc = preprocessing.LabelEncoder()\n",
    "#lab_enc.fit(data['gender'])\n",
    "#data['gender']=lab_enc.transform(data['gender'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dat[0],data.label, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "lr=LogisticRegression()\n",
    "sgd=lr.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,sgd))\n",
    "print(classification_report(Y_test,sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(\"SVC\")\n",
    "svm = SVC(kernel='linear', C=2.0, random_state=500)\n",
    "predictionSVM=svm.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,predictionSVM))\n",
    "print(classification_report(Y_test,predictionSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "pred=calibrated_clf.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,pred))\n",
    "print(classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=2,max_depth=2) \n",
    "predictionRF=rfc.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,predictionRF))\n",
    "print(classification_report(Y_test,predictionRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf2 = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "clf1 = LogisticRegression()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('sgd', clf2)],voting='hard')\n",
    "predictionVC=eclf1.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,predictionVC))\n",
    "print(classification_report(Y_test,predictionVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting twitterSentiment[] list into dataframe for serving it to keras tokenizer\n",
    "dataSetFinal = pd.DataFrame(np.array(twitterSentiment))\n",
    "dataSetFinal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(num_words=1500, lower=True,split=' ',filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(dataSetFinal[0].values)\n",
    "#print(tokenizer.word_index)  # To see the dicstionary\n",
    "X = tokenizer.texts_to_sequences(dataSetFinal[0].values)\n",
    "X = tensorflow.keras.preprocessing.sequence.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "#Deep Learning Network Structure\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(1500,100, input_length=X.shape[1]))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(100))\n",
    "model_conv.add(Dense(2, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_conv.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy','mae',keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "Y = pd.get_dummies(data['label']).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.30)\n",
    "#Here we train the Network.\n",
    "pred=model_conv.fit(X_train, Y_train, batch_size =batch_size, epochs =10, verbose =2,validation_data=(X_valid,Y_valid))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "score=model_conv.evaluate(X_valid,Y_valid,verbose=2,batch_size=batch_size)\n",
    "#keras.metrics.binary_accuracy(Y_valid,pred)\n",
    "print(\"score: %.2f\" %(score[0]))\n",
    "print(\"validation accuracy: %.2f\" % (score[1]))\n",
    "print(\"recall: %.2f\" %(score[4]))\n",
    "print(\"Precision: %.2f\" % (score[3]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
