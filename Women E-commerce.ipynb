{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_metrics\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Embedding\n",
    "# using the variable sw to hold all stopwords that are in English\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataset\n",
    "data=pd.read_csv('Womens Clothing E-Commerce Reviews.csv')\n",
    "#data=pd.read_csv('train.csv',encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dresses           6319\n",
       "Knits             4843\n",
       "Blouses           3097\n",
       "Sweaters          1428\n",
       "Pants             1388\n",
       "Jeans             1147\n",
       "Fine gauge        1100\n",
       "Skirts             945\n",
       "Jackets            704\n",
       "Lounge             691\n",
       "Swim               350\n",
       "Outerwear          328\n",
       "Shorts             317\n",
       "Sleep              228\n",
       "Legwear            165\n",
       "Intimates          154\n",
       "Layering           146\n",
       "Trend              119\n",
       "Casual bottoms       2\n",
       "Chemises             1\n",
       "Name: Class Name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                      0\n",
      "Unnamed: 0                 0\n",
      "Clothing ID                0\n",
      "Age                        0\n",
      "Title                      0\n",
      "Review Text                0\n",
      "Rating                     0\n",
      "Recommended IND            0\n",
      "Positive Feedback Count    0\n",
      "Division Name              0\n",
      "Department Name            0\n",
      "Class Name                 0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0      2           2         1077   60  Some major design flaws   \n",
       "1      3           3         1049   50         My favorite buy!   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  I had such high hopes for this dress and reall...       3                0   \n",
       "1  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0         General         Dresses    Dresses  \n",
       "1                        0  General Petite         Bottoms      Pants  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(inplace=True)\n",
    "print(data.isnull().sum())\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>high hopes dress really wanted work me. initia...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>love, love, love jumpsuit. fun, flirty, fabulo...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0      2           2         1077   60  Some major design flaws   \n",
       "1      3           3         1049   50         My favorite buy!   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  high hopes dress really wanted work me. initia...       3                0   \n",
       "1  love, love, love jumpsuit. fun, flirty, fabulo...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0         General         Dresses    Dresses  \n",
       "1                        0  General Petite         Bottoms      Pants  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying pre-processing steps to remove stopwords and words of size less than 2\n",
    "data['Review Text'] = data['Review Text'].apply(lambda x: x.split())\n",
    "wordsEng = stopwords.words('english')\n",
    "data['Review Text'] = data['Review Text'].apply(lambda x:[item for item in x if item not in wordsEng])\n",
    "data['Review Text'] = data['Review Text'].apply(lambda x: [w for w in x if len(w)>2])\n",
    "data['Review Text'] = data['Review Text'].apply(lambda x: \" \".join(x))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing airline company names as pre-processing\n",
    "testList=[]\n",
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "for t in range(len(data)):\n",
    "    testList.append(strip_all_entities(strip_links(data['Review Text'][t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high hopes dress really wanted work me initial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This shirt flattering due adjustable front tie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love tracy reese dresses one petite feet tall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aded basket hte last mintue see would look lik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  high hopes dress really wanted work me initial...\n",
       "1  love love love jumpsuit fun flirty fabulous ev...\n",
       "2  This shirt flattering due adjustable front tie...\n",
       "3  love tracy reese dresses one petite feet tall ...\n",
       "4  aded basket hte last mintue see would look lik..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting testList[] list into dataframe for further processing\n",
    "dat = pd.DataFrame(np.array(testList))\n",
    "dat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying pre-processing to remove special symbols, numbers and converting into lower case\n",
    "sw = stopwords.words('english')\n",
    "twitterSentiment=[]\n",
    "for i in range(len(dat)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ',dat[0][i])\n",
    "    review = re.sub('[/(){}\\[\\]\\|@!,;]', ' ',dat[0][i])\n",
    "    review = re.sub('[^0-9a-zA-Z #+_♥️]', ' ',dat[0][i])#Remove bad symbols\n",
    "    \n",
    "    review = re.sub(r'\\d+', '',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [token for token in review if token not in sw]\n",
    "    review=' '.join(review)\n",
    "    review=' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",review).split())\n",
    "    twitterSentiment.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train = count_vectorizer.fit_transform(X_train)\n",
    "X_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import preprocessing\n",
    "#lab_enc = preprocessing.LabelEncoder()\n",
    "#lab_enc.fit(data['gender'])\n",
    "#data['gender']=lab_enc.transform(data['gender'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dat[0],data.Rating, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6290896762163078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.04      0.07       219\n",
      "           2       0.32      0.07      0.11       456\n",
      "           3       0.36      0.38      0.37       674\n",
      "           4       0.43      0.26      0.32      1256\n",
      "           5       0.71      0.94      0.81      3294\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.52      0.34      0.34      5899\n",
      "weighted avg       0.59      0.63      0.58      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "lr=LogisticRegression()\n",
    "sgd=lr.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,sgd))\n",
    "print(classification_report(Y_test,sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.6202746228174267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.24      0.31       219\n",
      "           2       0.30      0.23      0.26       456\n",
      "           3       0.35      0.42      0.38       674\n",
      "           4       0.41      0.31      0.35      1256\n",
      "           5       0.77      0.86      0.81      3294\n",
      "\n",
      "    accuracy                           0.62      5899\n",
      "   macro avg       0.46      0.41      0.42      5899\n",
      "weighted avg       0.60      0.62      0.60      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(\"SVC\")\n",
    "svm = SVC(kernel='linear', C=2.0, random_state=500)\n",
    "predictionSVM=svm.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,predictionSVM))\n",
    "print(classification_report(Y_test,predictionSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6287506357009662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.16      0.23       219\n",
      "           2       0.28      0.08      0.12       456\n",
      "           3       0.36      0.42      0.39       674\n",
      "           4       0.40      0.24      0.30      1256\n",
      "           5       0.74      0.93      0.82      3294\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.44      0.37      0.37      5899\n",
      "weighted avg       0.58      0.63      0.58      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "pred=calibrated_clf.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,pred))\n",
    "print(classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5855229699949144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       219\n",
      "           2       0.40      0.01      0.03       456\n",
      "           3       0.38      0.15      0.22       674\n",
      "           4       0.34      0.06      0.10      1256\n",
      "           5       0.61      0.99      0.75      3294\n",
      "\n",
      "    accuracy                           0.59      5899\n",
      "   macro avg       0.35      0.24      0.22      5899\n",
      "weighted avg       0.49      0.59      0.47      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=50) \n",
    "predictionRF=rfc.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,predictionRF))\n",
    "print(classification_report(Y_test,predictionRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6316324800813697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.15      0.21       219\n",
      "           2       0.28      0.12      0.16       456\n",
      "           3       0.37      0.41      0.39       674\n",
      "           4       0.44      0.23      0.30      1256\n",
      "           5       0.73      0.93      0.82      3294\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.44      0.37      0.38      5899\n",
      "weighted avg       0.58      0.63      0.59      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf2 = SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "clf1 = LogisticRegression()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('sgd', clf2)],voting='hard')\n",
    "predictionVC=eclf1.fit(X_train, Y_train).predict(X_test)\n",
    "print(accuracy_score(Y_test,predictionVC))\n",
    "print(classification_report(Y_test,predictionVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high hopes dress really wanted work initially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  high hopes dress really wanted work initially ...\n",
       "1  love love love jumpsuit fun flirty fabulous ev..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting twitterSentiment[] list into dataframe for serving it to keras tokenizer\n",
    "dataSetFinal = pd.DataFrame(np.array(twitterSentiment))\n",
    "dataSetFinal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tensorflow.keras.preprocessing.text.Tokenizer(num_words=5000, lower=True,split=' ',filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(dataSetFinal[0].values)\n",
    "#print(tokenizer.word_index)  # To see the dicstionary\n",
    "X = tokenizer.texts_to_sequences(dataSetFinal[0].values)\n",
    "X = tensorflow.keras.preprocessing.sequence.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "#Deep Learning Network Structure\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(2500,100, input_length=X.shape[1]))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(100))\n",
    "model_conv.add(Dense(5, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_conv.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy','mae',keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "#Deep Learning Network Structure\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(5000,100, input_length=X.shape[1]))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(LSTM(100))\n",
    "model_conv.add(Dense(5, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy','mae',keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13763 samples, validate on 5899 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "Y = pd.get_dummies(data['Rating']).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.30)\n",
    "#Here we train the Network.\n",
    "pred=model_conv.fit(X_train, Y_train, batch_size =batch_size, epochs =10, verbose =2,validation_data=(X_valid,Y_valid))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13763 samples, validate on 5899 samples\n",
      "Epoch 1/25\n",
      " - 28s - loss: 1.1358 - acc: 0.5595 - mean_absolute_error: 0.2360 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.9453 - val_acc: 0.5984 - val_mean_absolute_error: 0.1930 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.8759 - acc: 0.6313 - mean_absolute_error: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.8966 - val_acc: 0.6143 - val_mean_absolute_error: 0.1985 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.7929 - acc: 0.6701 - mean_absolute_error: 0.1754 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.8840 - val_acc: 0.6371 - val_mean_absolute_error: 0.1805 - val_precision: 0.4615 - val_recall: 0.0316\n",
      "Epoch 4/25\n",
      " - 22s - loss: 0.7410 - acc: 0.6906 - mean_absolute_error: 0.1652 - precision: 0.5870 - recall: 0.0539 - val_loss: 0.9114 - val_acc: 0.6311 - val_mean_absolute_error: 0.1781 - val_precision: 0.2857 - val_recall: 0.0105\n",
      "Epoch 5/25\n",
      " - 22s - loss: 0.6916 - acc: 0.7166 - mean_absolute_error: 0.1546 - precision: 0.5714 - recall: 0.1437 - val_loss: 0.9170 - val_acc: 0.6223 - val_mean_absolute_error: 0.1805 - val_precision: 0.4630 - val_recall: 0.1316\n",
      "Epoch 6/25\n",
      " - 22s - loss: 0.6542 - acc: 0.7343 - mean_absolute_error: 0.1478 - precision: 0.6215 - recall: 0.2196 - val_loss: 0.9937 - val_acc: 0.6360 - val_mean_absolute_error: 0.1675 - val_precision: 0.5172 - val_recall: 0.0789\n",
      "Epoch 7/25\n",
      " - 22s - loss: 0.6245 - acc: 0.7490 - mean_absolute_error: 0.1411 - precision: 0.6641 - recall: 0.3393 - val_loss: 0.9729 - val_acc: 0.6208 - val_mean_absolute_error: 0.1759 - val_precision: 0.4651 - val_recall: 0.1053\n",
      "Epoch 8/25\n",
      " - 22s - loss: 0.5956 - acc: 0.7627 - mean_absolute_error: 0.1348 - precision: 0.6926 - recall: 0.3733 - val_loss: 1.0320 - val_acc: 0.6091 - val_mean_absolute_error: 0.1760 - val_precision: 0.3411 - val_recall: 0.2316\n",
      "Epoch 9/25\n",
      " - 22s - loss: 0.5588 - acc: 0.7806 - mean_absolute_error: 0.1265 - precision: 0.7695 - recall: 0.4930 - val_loss: 1.0453 - val_acc: 0.5972 - val_mean_absolute_error: 0.1793 - val_precision: 0.3188 - val_recall: 0.2316\n",
      "Epoch 10/25\n",
      " - 23s - loss: 0.5297 - acc: 0.7960 - mean_absolute_error: 0.1196 - precision: 0.7457 - recall: 0.5210 - val_loss: 1.0983 - val_acc: 0.5891 - val_mean_absolute_error: 0.1831 - val_precision: 0.3129 - val_recall: 0.2421\n",
      "Epoch 11/25\n",
      " - 26s - loss: 0.5069 - acc: 0.8026 - mean_absolute_error: 0.1154 - precision: 0.7851 - recall: 0.5908 - val_loss: 1.1243 - val_acc: 0.6082 - val_mean_absolute_error: 0.1729 - val_precision: 0.3857 - val_recall: 0.1421\n",
      "Epoch 12/25\n",
      " - 29s - loss: 0.4767 - acc: 0.8149 - mean_absolute_error: 0.1081 - precision: 0.8174 - recall: 0.5808 - val_loss: 1.1823 - val_acc: 0.5976 - val_mean_absolute_error: 0.1742 - val_precision: 0.3007 - val_recall: 0.2263\n",
      "Epoch 13/25\n",
      " - 27s - loss: 0.4543 - acc: 0.8282 - mean_absolute_error: 0.1029 - precision: 0.8095 - recall: 0.6108 - val_loss: 1.2395 - val_acc: 0.5996 - val_mean_absolute_error: 0.1710 - val_precision: 0.3435 - val_recall: 0.2368\n",
      "Epoch 14/25\n",
      " - 27s - loss: 0.4260 - acc: 0.8352 - mean_absolute_error: 0.0965 - precision: 0.8346 - recall: 0.6647 - val_loss: 1.2596 - val_acc: 0.5932 - val_mean_absolute_error: 0.1742 - val_precision: 0.3083 - val_recall: 0.1947\n",
      "Epoch 15/25\n",
      " - 27s - loss: 0.4042 - acc: 0.8468 - mean_absolute_error: 0.0909 - precision: 0.8544 - recall: 0.7026 - val_loss: 1.3100 - val_acc: 0.6003 - val_mean_absolute_error: 0.1694 - val_precision: 0.3243 - val_recall: 0.1895\n",
      "Epoch 16/25\n",
      " - 27s - loss: 0.3825 - acc: 0.8571 - mean_absolute_error: 0.0863 - precision: 0.8697 - recall: 0.7325 - val_loss: 1.3275 - val_acc: 0.5809 - val_mean_absolute_error: 0.1784 - val_precision: 0.3208 - val_recall: 0.1789\n",
      "Epoch 17/25\n",
      " - 26s - loss: 0.3698 - acc: 0.8620 - mean_absolute_error: 0.0827 - precision: 0.8714 - recall: 0.7305 - val_loss: 1.3479 - val_acc: 0.5911 - val_mean_absolute_error: 0.1739 - val_precision: 0.3052 - val_recall: 0.2474\n",
      "Epoch 18/25\n",
      " - 27s - loss: 0.3439 - acc: 0.8724 - mean_absolute_error: 0.0773 - precision: 0.8843 - recall: 0.7625 - val_loss: 1.4632 - val_acc: 0.6001 - val_mean_absolute_error: 0.1679 - val_precision: 0.2956 - val_recall: 0.2474\n",
      "Epoch 19/25\n",
      " - 27s - loss: 0.3393 - acc: 0.8740 - mean_absolute_error: 0.0760 - precision: 0.8901 - recall: 0.7924 - val_loss: 1.5170 - val_acc: 0.5893 - val_mean_absolute_error: 0.1735 - val_precision: 0.2826 - val_recall: 0.2053\n",
      "Epoch 20/25\n",
      " - 27s - loss: 0.3198 - acc: 0.8839 - mean_absolute_error: 0.0708 - precision: 0.8742 - recall: 0.7764 - val_loss: 1.5067 - val_acc: 0.5847 - val_mean_absolute_error: 0.1753 - val_precision: 0.2950 - val_recall: 0.2158\n",
      "Epoch 21/25\n",
      " - 27s - loss: 0.3045 - acc: 0.8864 - mean_absolute_error: 0.0685 - precision: 0.8959 - recall: 0.7904 - val_loss: 1.5666 - val_acc: 0.5682 - val_mean_absolute_error: 0.1817 - val_precision: 0.2527 - val_recall: 0.2421\n",
      "Epoch 22/25\n",
      " - 26s - loss: 0.2955 - acc: 0.8914 - mean_absolute_error: 0.0658 - precision: 0.9199 - recall: 0.8024 - val_loss: 1.5583 - val_acc: 0.5637 - val_mean_absolute_error: 0.1814 - val_precision: 0.2652 - val_recall: 0.2526\n",
      "Epoch 23/25\n",
      " - 27s - loss: 0.2768 - acc: 0.8970 - mean_absolute_error: 0.0626 - precision: 0.9015 - recall: 0.8224 - val_loss: 1.6291 - val_acc: 0.5926 - val_mean_absolute_error: 0.1705 - val_precision: 0.2899 - val_recall: 0.2579\n",
      "Epoch 24/25\n",
      " - 27s - loss: 0.2649 - acc: 0.9024 - mean_absolute_error: 0.0594 - precision: 0.9152 - recall: 0.8184 - val_loss: 1.7112 - val_acc: 0.5801 - val_mean_absolute_error: 0.1747 - val_precision: 0.2810 - val_recall: 0.2263\n",
      "Epoch 25/25\n",
      " - 27s - loss: 0.2571 - acc: 0.9080 - mean_absolute_error: 0.0573 - precision: 0.9120 - recall: 0.8483 - val_loss: 1.7398 - val_acc: 0.5796 - val_mean_absolute_error: 0.1746 - val_precision: 0.2675 - val_recall: 0.2211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xba490cc438>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for  LSTM only\n",
    "batch_size=128\n",
    "Y = pd.get_dummies(data['Rating']).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.30)\n",
    "#Here we train the Network.\n",
    "pred=model_conv.fit(X_train, Y_train, batch_size =batch_size, epochs =25, verbose =2,validation_data=(X_valid,Y_valid))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 1.74\n",
      "validation accuracy: 0.58\n",
      "recall: 0.22\n",
      "Precision: 0.27\n"
     ]
    }
   ],
   "source": [
    "#LSTM Only\n",
    "score=[]\n",
    "score=model_conv.evaluate(X_valid,Y_valid,verbose=2,batch_size=batch_size)\n",
    "#keras.metrics.binary_accuracy(Y_valid,pred)\n",
    "print(\"score: %.2f\" %(score[0]))\n",
    "print(\"validation accuracy: %.2f\" % (score[1]))\n",
    "print(\"recall: %.2f\" %(score[4]))\n",
    "print(\"Precision: %.2f\" % (score[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.40\n",
      "validation accuracy: 0.82\n",
      "recall: 0.00\n",
      "Precision: 0.00\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "score=[]\n",
    "score=model_conv.evaluate(X_valid,Y_valid,verbose=2,batch_size=batch_size)\n",
    "#keras.metrics.binary_accuracy(Y_valid,pred)\n",
    "print(\"score: %.2f\" %(score[0]))\n",
    "print(\"validation accuracy: %.2f\" % (score[1]))\n",
    "print(\"recall: %.2f\" %(score[4]))\n",
    "print(\"Precision: %.2f\" % (score[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data['Rating'])\n",
    "data = data\n",
    "tokenized_data = data['Review Text'].apply(lambda x: x.split())\n",
    "model_w2v = Word2Vec( tokenized_data, size=200, window=5, min_count=2,sg = 1, hs = 0, negative = 10, workers= 2, seed = 34)\n",
    "model_w2v.train(tokenized_data, total_examples= len(data['Review Text']), epochs=20)\n",
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "        return vec\n",
    "wordvec_arrays = np.zeros((len(tokenized_data), 200))\n",
    "for i in range(len(tokenized_data)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_data[i], 200)\n",
    "data_feature_3 = pd.DataFrame(wordvec_arrays)\n",
    "df_tex = data_feature_3\n",
    "df_cat = data['Rating']\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_tex, df_cat, test_size=0.3, random_state=2, stratify=df_cat)\n",
    "y_train = y_train.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6314629598236989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.15      0.24       207\n",
      "           2       0.30      0.09      0.14       408\n",
      "           3       0.41      0.37      0.39       739\n",
      "           4       0.41      0.25      0.31      1287\n",
      "           5       0.72      0.94      0.81      3258\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.47      0.36      0.38      5899\n",
      "weighted avg       0.58      0.63      0.58      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "lr=LogisticRegression()\n",
    "sgdW2V=lr.fit(x_train, y_train).predict(x_test)\n",
    "print(accuracy_score(y_test,sgdW2V))\n",
    "print(classification_report(y_test,sgdW2V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867096117986099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       207\n",
      "           2       0.67      0.00      0.01       408\n",
      "           3       0.43      0.21      0.28       739\n",
      "           4       0.31      0.08      0.12      1287\n",
      "           5       0.61      0.98      0.76      3258\n",
      "\n",
      "    accuracy                           0.59      5899\n",
      "   macro avg       0.40      0.25      0.23      5899\n",
      "weighted avg       0.51      0.59      0.48      5899\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=52,max_depth=10) \n",
    "predRfc=rfc.fit(x_train, y_train).predict(x_test)\n",
    "print(accuracy_score(y_test,predRfc))\n",
    "print(classification_report(y_test,predRfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63383624343109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.19      0.26       207\n",
      "           2       0.29      0.10      0.14       408\n",
      "           3       0.40      0.44      0.42       739\n",
      "           4       0.41      0.22      0.29      1287\n",
      "           5       0.73      0.93      0.82      3258\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.45      0.38      0.39      5899\n",
      "weighted avg       0.58      0.63      0.59      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "clf = linear_model.SGDClassifier(max_iter=1100, tol=1e-3)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
    "pred=calibrated_clf.fit(x_train, y_train).predict(x_test)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6316324800813697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.12      0.18       207\n",
      "           2       0.32      0.13      0.18       408\n",
      "           3       0.43      0.42      0.43       739\n",
      "           4       0.44      0.20      0.27      1287\n",
      "           5       0.71      0.95      0.81      3258\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.46      0.36      0.37      5899\n",
      "weighted avg       0.58      0.63      0.58      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='log')\n",
    "lr=LogisticRegression()\n",
    "vc=VotingClassifier(estimators=[('lr', lr), ('clf', clf),],voting='hard')\n",
    "sgd=vc.fit(x_train, y_train).predict(x_test)\n",
    "print(accuracy_score(y_test,sgd))\n",
    "print(classification_report(y_test,sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6314629598236989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.12      0.18       207\n",
      "           2       0.31      0.05      0.09       408\n",
      "           3       0.38      0.54      0.44       739\n",
      "           4       0.42      0.19      0.27      1287\n",
      "           5       0.74      0.93      0.82      3258\n",
      "\n",
      "    accuracy                           0.63      5899\n",
      "   macro avg       0.45      0.37      0.36      5899\n",
      "weighted avg       0.58      0.63      0.58      5899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=2.0, random_state=2)\n",
    "svmPred=svm.fit(x_train, y_train).predict(x_test)\n",
    "print(accuracy_score(y_test,svmPred))\n",
    "print(classification_report(y_test,svmPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
